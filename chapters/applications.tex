%**************************************
\chapter{Applications} % (fold)
\label{cha:applications}
%**************************************

This chapter is meant as a brief evocation of the potential of a fully
annotated corpus of the papyri for further research.

\section{Collaborative editing} % (fold)
\label{sec:collaborativeediting}

The IDP project is heading into crowdsourcing territory at full steam, and
excluding our own work from this movement would be inserting a shrill note into
this symphony. All data is placed on GitHub at
\url{https://github.com/sinopeus/tjufy}, freely accessible and editable for
all. 

This opens promising avenues of inquiry that do not have a direct relation
to this thesis. For instance, it can in the future be integrated into SoSOL and
absorbed into the larger codebase for the IDP project if it does not create too
much overhead for the current developers (the technical back end of the IDP
seems to be labyrinthine and adding new layers of complexity might be
off-putting). It could even grow into a separate project which itself could be
linked to papyri.info as the HGV, APIS and Trismegistos currently are, by a
common system of indexation.

Making the code publically available to all also has the advantage of the
public eye inspecting the texts; using solely automatic analysis is bound to
deliver an inaccurate result, however small that inaccuracy may be, as creating
a NLP engine perfectly capable of understanding language would be the
equivalent of creating a perfect artificial intelligence. Therefore,
considering the size of the corpus, we must rely upon the intelligence of the
community. In the same way open source software is often among the best of
software due to public inspection, the potential for a crowdsourced corpus is
immense.

% section Collaborative editing (end)

\section{Corpus-based grammars and lexica} % (fold)
\label{sec:corpusbasedgrammars}

Expanding our method to other texts might bring the benefit of comprehensive
corpus-based grammars and lexica, which can integrate available data on the fly
and create a self-updating and reliable web of grammatical knowledge. Instead
of focusing mainly upon a few choice authors or laboriously trudging through
the huge wealth of ancient Greek literature to linearly create lexica and
grammars, we could harness all of it at once in a quantitatively precise and
easily visualisable way.

\url{http://www.digitalhumanities.org/dhq/vol/003/1/000033/000033.html}

% section Corpus-based grammars (end)

\section{Historical and variational linguistics} % (fold)
\label{sec:histlinguistics}

The language of the papyri has an important role to play in the historical
linguistics of Greek; once a full annotation has been achieved, it could be
possible to implement the same methods used for synchronic language processing
to map language changes in a statistical way; it could be possible to estimate
the transition probabilities for diachronic grammatical evolutions, which has
the potential to create a picture of the evolution of Greek that would be both
comprehensive and precise. It even has potential on a comparative level; given
the long history and meandering evolutionary trajectory of the Greek language,
we could observe from the data catalysts for language evolution in one
direction or the other and apply that comparatively.

We might also win valuable insight into language diversity in Egypt; using the
paraliterary data already available from the Trismegistos, linguistic phenomena
and evolutions could be visualised on a map and give insight into the diatopic,
diastratic and diaphasic variation of Egyptian koin\^e, much in the way of
modern dialect survey maps but directly linked to the original texts.

% section Historical linguistics (end)

\section{Textual criticism} % (fold)
\label{sec:textualcriticism}

Textual criticism, too, could benefit from improved access to linguistic data;
dubious \textit{passus} could be disambiguated by comparing them to similar
instances in papyri from the same period and adapting constructions and words
from them.  This technique is harnessed by \citet{mimno2009}, who use the
techniques of statistical NLP solely for these specific critical problems.
Though textual criticism will for the foreseeable future still necessitate
trained papyrologists, the need for a very in-depth knowledge of the corpus of
papyri can be greatly reduced by calling upon data from other parts of the
corpus to present a series of statistically possible solutions for textual
issues.

% section Textual criticism (end)


\section{Named entity recognition} % (fold)
\label{sec:ner}

Named entity recognition is a subdiscipline in natural language processing
which is concerned with the automatic extraction and localisation of all kinds
of names from texts. It has been used extensively in literary texts with a view
to discern the importance of certain characters throughout the text. The KU
Leuven's long-standing Prosopographia Ptolemaica project, which aims to be a
repository of all inhabitants of Egypt between 300 and 30 B.C., could easily
benefit from these techniques. The abundant manual labour that has gone into
the project could be fed as training data to and then supplemented by a named
entity recognition engine that could also categorise personal names by any
criteria and establish contextual relations between them. To take a very
rudimentary example, the name 'Alexander' could be retrieved in all texts and a
cluster of related names generated, so that related individuals may be placed
in a web of relations; or we could ask, by combining the already present
linguistic annotation, to display all adjectives which accompany the name
'Alexander'.

It could even go further than this and also include other particular names,
such as places, distances, monetary units, weights, and so on. Historians could
create a comprehensive overview of, for instance, the inflation of Egyptian
currency, or map out trade connections using a search for all mentions of
currency, weight and places which are in proximity to each other.

% section Named entity recognition (end)

% chapter Applications (end)

