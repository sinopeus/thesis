
%************************************************
\chapter{Analysis}
\label{chp:analysis} %\minitoc\mtcskip
%************************************************

In this chapter, the main objectives of this thesis are outlined more
precisely, placed in their scholarly context and given motivation. We
consider a \textbf{dual goal}: creating a statistical language model
of ancient Greek using machine learning techniques, and applying this
model to a corpus of documentary papyri.

We propose that both problems have not been tackled in an adequate way
up to now.

\section{Problem statement}

\subsection{A language model for ancient Greek}
\subsubsection{Definitions \& objectives} A \textbf{language model} is a statistical
model designed to assign probability scores to word sequences;
however, it is key that the model is also able to apply the knowledge
of these probabilities to specific problems in the analysis of
language. The problems we want to tackle are classical
\textbf{morphological analysis} and \textbf{syntactic analysis}.

The first problem largely corresponds with what is called
\textbf{part-of-speech tagging} in the natural language processing
jargon. For any token in the sentence, given its context, we want to
model to produce a morphological analysis, which produces not only the
part-of-speech \textit{stricto sensu}, but all concomitant information
as well: voice, tense, mood, case, gender, number, person, \ldots

The second problem corresponds with what is called \textbf{shallow
parsing} (or \textbf{chunking}). Given a sequence of words, we want to
identify the main grammatical components of this sequence.  This type
of parsing stands in contrast with \textbf{deep parsing}, which aims
to produce full syntactic analyses of entire sentences, including
\textbf{parse trees}, which give a graphical representation of their
syntactic structure.

\subsubsection{Technique} 
In general, a language model is created by choosing a modeling
criterium and applying it to a a large set of observations. These
observations may be raw word sequences or annotated word sequences,
depending on the chosen criterium. Each observation is coupled with an
adjustment of the language model to maximise the score for that
particular observation type. The larger the set, the better, as each
observation makes the model a better reflection of linguistic reality.

We choose a two-phase training method based on deep neural networks,
which is explained and illustrated in further detail and more
concretely in subsequent chapters.

The first phase attempts to create a simple probabilistic model using
a little linguistic knowledge as possible: the goal is to assign
scores to word sequences that are proportional to the probability of
these sequences being `correct', i. e. likely to appear in real
linguist data. Maximising these scores is achieved by corrupting data
from the observation corpus; the model is then adjusted to give the
real observation a higher score than the corrupted observation.

The second phase is implemented on top of the first and consists in
using a new observation corpus, this time equipped with
annotation. These annotations are transformed into vectors with a set
number of components, which each represent a linguistic feature. The
scores returned by the model are now in vector form, each component
being a score similar to the one developed in the first phase.


\subsection{Annotating a corpus of documentary papyri}
\subsubsection{The corpus: scale and complexity}
The object corpus contains about 4.5 million words. Given the nature
of the provided material, the state of these texts varies from
extremely corrupted to nearly pristine. The texts are dated from 300BC
to 800AD, spanning more than a millennium; many different discourse
registers are represented, although literary texts are not included.

Linguistically speaking, this is a less than desirable state of
affairs. By virtue of the characteristics mentioned in the previous
paragraph, the corpus will contains thousands of unorthodox or
corrupted word forms. This heightens the complexity of the task at
hand, and we cannot but lower our standards for accuracy if we wish to
proceed in an automated way. Nevertheless, it is possible to develop a
model which is able to make inferences (albeit limited ones) about
unknown forms.

% The second major obstacle is the ancient Greek language itself. Though
% it has lost a great deal of morphological complexity in its evolution
% towards its current state, the Greek of Hellenistic, Roman and
% Byzantine times is still marginally more complex than a language like
% English, which is the target language for most research in natural
% language processing. Commonly used techniques in NLP are still
% applicable and have been used with success on other morphologically
% complex languages, but given the size of the tag set for ancient Greek
% morphology and syntax, it is wise to preprocess the corpus to reduce
% the amount of factors that must be held into account in the creation
% of our model.


% Another interesting treebank is that hosted by the PROIEL
% \footnote{Short for 'Pragmatic Resources for Indo-European Languages'}
% project, which aims to offer morphologically and syntactically
% annotated multilingual corpora for comparative purposes. The project,
% contrary to the Perseus treebank, seems to be alive and well at the
% time of this writing. This corpus contains data which can be of much
% help: large swathes of Herodotus, the New Testament, and the writings
% of the Byzantine historian George Sphrantzes are fully annotated, both
% morphologically and syntactically. Since the Greek of the papyri is
% syntactically similar to the Greek of these texts, we are afforded a
% good basis for our system.

% Nevertheless, probabilistic natural language processing is by virtue
% of its underlying principles hungry for ever more data in order to
% achieve high performance. Therefore, we somehow need to create a
% larger foundation upon which we can construct a performant
% architecture. Here, we can take our cues from the field of machine
% learning, where the state-of-the-art approaches rely on massive
% amounts of unlabeled data which are then submitted to analysis. The
% exact approaches chosen are explained in detail in the next chapter.

\section{Context}

The problem of Greek morphological analysis can essentially be
considered solved for individual words; contextual disambiguation, on
the other hand, has only been attempted once with mitigated
success. The idea of designing a system to automatically process
ancient Greek as envisioned in this work was originally inspired by
the work of R. Whaling and H. Dik [\cite{dik2008,dik2009}, see
\ref{sec:dikwhaling} as well], who used a purely supervised method for
tagging a corpus of classical Greek. They trained H. Schmid's
TreeTagger using a relatively small corpus of annotated Greek and
proceeded to tag their corpus with it, offsetting the relatively large
error rate with manual work done by graduate students at the
University of Chicago. Whaling and Dik's method enabled them to
annotate the corpus in much less time than would have been necessary
would the annotation process have been executed manually.

An early prototype of this thesis attempted to use similar supervised
methods to annotate the corpus of the papyri. Despite high
expectations, experience showed that the lack of extensive annotated
corpora is a severe hindrance, as the main way to improve the accuracy
of any NLP system is to offer it more training data. Feeding 400.000
words as training data to the Stanford POS Tagger resulted in a measly
60\% accuracy on a validation set held out from the training corpus.

Recent literature in the field revealed that state-of-the-art results
were being achieved using a combination of unsupervised and supervised
learning techniques, dubbed semi-supervised approaches. Unsupervised
approaches can make use of unannotated data as a preparation for
supervised training, and work by trying to divide the raw data into
clusters on the basis of various criteria. Notably, R. Collobert and
others developed a versatile architecture which achieved high accuracy
on several NLP tasks and required a relatively low amount of
optimisation. See \citet{collobert2008}, \citet{collobert-2011}. Accuracy
for POS tagging reached up to 97.20\%, while for chunking, scores of
up to 93.63\% were achieved; similarly high results were achieved for
named entity recognition and semantic role labeling. this is an
impressive performance given the fact that most of the architecture is
shared among all tasks and the majority of the parameters of the
system are inferred through unsupervised methods. 

Given that far larger amounts of raw textual material are available
for ancient Greek, it seems that this kind of technique is suited to
the problem at hand. The 400.000 word training corpus used in the
experiment with the Stanford POS Tagger is much smaller and limited
than corpora like that offered by the Perseus project (about 7M words)
and the TLG (about 109M words at last count, though these are not
freely available). Making use of this untapped resource is
desirable. \hyperref[chp:design]{Chapter \ref*{chp:design}} is
dedicated to an overview of the architecture; the approach followed in
\citet{collobert-2011} and \citet{turian2010word} is respected with
amendments and simplifications where needed in order to accommodate
for some characteristics of Greek (in particular the very high
complexity of its morphology requires a subtler approach). The exact
implementation of the system is left for
\hyperref[chp:implementation]{chapter \ref*{chp:implementation}}.

Most resources do provide morphological analysis, but there are very
few projects concerned with treebanks or databases of semantically
annotated Greek. The Perseus project, for instance, has developed a
dependency treebank for Latin and ancient Greek. It is an admirable
effort, but limited in scope and containing mainly poetry, which is in
itself valid training data, but certainly not sufficient training data
if we want our system to be able to analyse large amounts of prose.
What's more, the project seems to be lacking manpower and has lost
steam since its inception, the last update dates from 2012, more than
a year ago at the time of this writing.
\section{Motivation}
In which we show why our objectives are worthwhile, and how we may
profit from the completion of our objectives.
%% follow an objection-rebuttal scheme

% \begin{itemize}
% \item searchable corpus
% \item corpus-based grammar
% \end{itemize}